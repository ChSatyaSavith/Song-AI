{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1882c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5aa88339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n",
       "      <td>['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n",
       "      <td>[\"[Verse 1]\\nFound you when your heart was bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n",
       "      <td>['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3KkXRkHbMCARz0aVfEt68P</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n",
       "      <td>[\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  song_id                                             lyrics\n",
       "0  3e9HZxeyfWwjeyPAMmWSSQ  ['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...\n",
       "1  5p7ujcrUXASCNwRaWNHR1C  [\"[Verse 1]\\nFound you when your heart was bro...\n",
       "2  2xLMifQCjDGFmkHkpNLD9h  ['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...\n",
       "3  3KkXRkHbMCARz0aVfEt68P                                                NaN\n",
       "4  1rqqCSm0Qe4I9rUvWncaom  [\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df = pd.read_csv(\"lyrics.csv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9040c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(x):\n",
    "    text = x['lyrics']\n",
    "    sections = text.split('\\\\n\\\\n')\n",
    "    \n",
    "    keys = {'Verse 1': np.nan,'Verse 2':np.nan,'Verse 3':np.nan,'Verse 4':np.nan, 'Chorus':np.nan}\n",
    "    \n",
    "    lyrics = str()\n",
    "    single_text = []\n",
    "    res = {}\n",
    "    \n",
    "    for s in sections:\n",
    "        key = s[s.find('[') + 1:s.find(']')].strip()\n",
    "        if ':' in key:\n",
    "            key = key[:key.find(':')]\n",
    "        if key in keys:\n",
    "            single_text += [x.lower().replace('(','').replace(')','').translate(translator) for x in s[s.find(']')+1:].split('\\\\n') if len(x) > 1]\n",
    "          \n",
    "        res['single_text'] =  ' \\n '.join(single_text)\n",
    "    return pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04c53aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04fd22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df.apply(split_text, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ada8da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>single_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n",
       "      <td>['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...</td>\n",
       "      <td>thank you next next \\n thank you next next \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n",
       "      <td>[\"[Verse 1]\\nFound you when your heart was bro...</td>\n",
       "      <td>tell me hows it feel sittin up there \\n feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n",
       "      <td>['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...</td>\n",
       "      <td>woo made this here with all the ice on in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n",
       "      <td>[\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t...</td>\n",
       "      <td>had to have high high hopes for a living \\n sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0bYg9bo50gSsH3LtXe2SQn</td>\n",
       "      <td>[\"[Intro]\\nI-I-I don't want a lot for Christma...</td>\n",
       "      <td>i dont want a lot for christmas \\n there is ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  song_id                                             lyrics  \\\n",
       "0  3e9HZxeyfWwjeyPAMmWSSQ  ['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...   \n",
       "1  5p7ujcrUXASCNwRaWNHR1C  [\"[Verse 1]\\nFound you when your heart was bro...   \n",
       "2  2xLMifQCjDGFmkHkpNLD9h  ['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...   \n",
       "4  1rqqCSm0Qe4I9rUvWncaom  [\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t...   \n",
       "5  0bYg9bo50gSsH3LtXe2SQn  [\"[Intro]\\nI-I-I don't want a lot for Christma...   \n",
       "\n",
       "                                         single_text  \n",
       "0  thank you next next \\n thank you next next \\n ...  \n",
       "1  tell me hows it feel sittin up there \\n feelin...  \n",
       "2  woo made this here with all the ice on in the ...  \n",
       "4  had to have high high hopes for a living \\n sh...  \n",
       "5  i dont want a lot for christmas \\n there is ju...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d3a73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame( df['single_text'] )\n",
    "sum_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "caf07648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you next next \\n thank you next next \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tell me hows it feel sittin up there \\n feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woo made this here with all the ice on in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had to have high high hopes for a living \\n sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i dont want a lot for christmas \\n there is ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         single_text\n",
       "0  thank you next next \\n thank you next next \\n ...\n",
       "1  tell me hows it feel sittin up there \\n feelin...\n",
       "2  woo made this here with all the ice on in the ...\n",
       "4  had to have high high hopes for a living \\n sh...\n",
       "5  i dont want a lot for christmas \\n there is ju..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f34c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_list = []\n",
    "\n",
    "frequencies = {}\n",
    "\n",
    "uncommon_words = set()\n",
    "\n",
    "MIN_FREQUENCY = 7\n",
    "\n",
    "MIN_SEQ = 5\n",
    "\n",
    "BATCH_SIZE =  32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "100c1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(text):\n",
    "    global text_as_list\n",
    "    text_as_list += [w for w in text.split(' ') if w.strip() != '' or w == '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bc103600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words:  2339637\n"
     ]
    }
   ],
   "source": [
    "sum_df['single_text'].apply( extract_text )\n",
    "\n",
    "print('Total words: ', len(text_as_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "498b57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in text_as_list:\n",
    "    frequencies[w] = frequencies.get(w, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8fb3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with less than 7 appearances: 26272\n",
      "Words with more than 7 appearances: 9163\n"
     ]
    }
   ],
   "source": [
    "uncommon_words = set([key for key in frequencies.keys() if frequencies[key] < MIN_FREQUENCY])\n",
    "\n",
    "words = sorted(set([key for key in frequencies.keys() if frequencies[key] >= MIN_FREQUENCY]))\n",
    "\n",
    "\n",
    "num_words = len(words)\n",
    "\n",
    "word_indices = dict((w, i) for i, w in enumerate(words))\n",
    "\n",
    "indices_word = dict((i, w) for i, w in enumerate(words))\n",
    "\n",
    "print('Words with less than {} appearances: {}'.format( MIN_FREQUENCY, len(uncommon_words)))\n",
    "\n",
    "print('Words with more than {} appearances: {}'.format( MIN_FREQUENCY, len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "36fa7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seqs = []\n",
    "\n",
    "end_seq_words = []\n",
    "\n",
    "for i in range(len(text_as_list) - MIN_SEQ ):\n",
    "    end_slice = i + MIN_SEQ + 1\n",
    "\n",
    "    if len( set(text_as_list[i:end_slice]).intersection(uncommon_words) ) == 0:\n",
    "        valid_seqs.append(text_as_list[i: i + MIN_SEQ])\n",
    "        end_seq_words.append(text_as_list[i + MIN_SEQ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "39782dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid sequences of size 5: 2087702\n",
      "[['minds', 'my', 'nine', 'my', 'pens'], ['pass', 'me', 'by', '\\n', 'do'], ['money', 'burnin', 'up', '\\n', 'they']]\n"
     ]
    }
   ],
   "source": [
    "print('Valid sequences of size {}: {}'.format(MIN_SEQ, len(valid_seqs)))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(valid_seqs, end_seq_words, test_size=0.02, random_state=42)\n",
    "\n",
    "print(X_train[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fccb8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "\n",
    "   # helper function to sample an index from a probability array\n",
    "\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "    preds = np.log(preds) / temperature\n",
    "\n",
    "    exp_preds = np.exp(preds)\n",
    "\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7744100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\n",
    "    print('Build model...')\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(input_dim=len(words), output_dim=1024))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    " \n",
    "    model.add(Dense(len(words)))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b024fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "34b1c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 1024)        9382912   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              1180672   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9163)              2354891   \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 9163)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,918,475\n",
      "Trainable params: 12,918,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "022d193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "580e0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_index = np.random.randint(len(X_train+X_test))\n",
    "seed = (X_train+X_test)[seed_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c9b11cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23837/1990099747.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    }
   ],
   "source": [
    "examples_file = open('examples.txt', \"w\")\n",
    "for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "\n",
    "    sentence = seed\n",
    "\n",
    "    examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
    "\n",
    "    examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
    "\n",
    "    examples_file.write(' '.join(sentence))\n",
    "\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "        x_pred = np.zeros((1, MIN_SEQ))\n",
    "\n",
    "        for t, word in enumerate(sentence):\n",
    "\n",
    "            x_pred[0, t] = word_indices[word]\n",
    "\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "        next_index = sample(preds, diversity)\n",
    "\n",
    "        next_word = indices_word[next_index]\n",
    "\n",
    "\n",
    "        sentence = sentence[1:]\n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "\n",
    "        examples_file.write(\" \"+next_word)\n",
    "\n",
    "    examples_file.write('\\n')\n",
    "\n",
    "examples_file.write('='*80 + '\\n')\n",
    "\n",
    "examples_file.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
